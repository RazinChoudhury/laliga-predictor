{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc1c89d-c2e8-4e10-8aad-12e0acbc8400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n",
      "Best Model: RandomForestClassifier(max_depth=3, min_samples_leaf=4, min_samples_split=10,\n",
      "                       random_state=1)\n",
      "Accuracy: 0.4875\n",
      "Precision: 0.36624082007343944\n",
      "Confusion Matrix:\n",
      "[[ 85   0  65]\n",
      " [ 47   0  53]\n",
      " [ 40   0 110]]\n",
      "Training data range: 2020-09-29 00:00:00 to 2023-12-23 00:00:00\n",
      "Testing data range: 2024-01-02 00:00:00 to 2024-05-26 00:00:00\n",
      "\n",
      "Training target distribution:\n",
      "2    0.362233\n",
      "0    0.361837\n",
      "1    0.275930\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Testing target distribution:\n",
      "0    0.375\n",
      "2    0.375\n",
      "1    0.250\n",
      "Name: target, dtype: float64\n",
      "         date             team opponent result  target  predicted\n",
      "26 2024-01-02    Real Sociedad   Alavés      D       1          2\n",
      "29 2024-01-12          Sevilla   Alavés      L       0          2\n",
      "21 2024-01-19            Cadiz   Alavés      L       0          0\n",
      "23 2024-01-26          Almeria   Alavés      L       0          2\n",
      "33 2024-02-03        Barcelona   Alavés      W       2          2\n",
      "32 2024-02-10       Villarreal   Alavés      D       1          2\n",
      "34 2024-02-18       Real Betis   Alavés      D       1          2\n",
      "31 2024-02-24         Mallorca   Alavés      D       1          0\n",
      "31 2024-03-04          Osasuna   Alavés      W       2          2\n",
      "31 2024-03-10   Rayo Vallecano   Alavés      L       0          0\n",
      "35 2024-03-16    Athletic Club   Alavés      W       2          2\n",
      "44 2024-03-31    Real Sociedad   Alavés      W       2          2\n",
      "31 2024-04-14          Granada   Alavés      W       2          2\n",
      "47 2024-04-21  Atletico Madrid   Alavés      L       0          2\n",
      "37 2024-04-27       Celta Vigo   Alavés      L       0          2\n",
      "37 2024-05-05         Valencia   Alavés      L       0          2\n",
      "39 2024-05-10           Girona   Alavés      D       1          0\n",
      "51 2024-05-14      Real Madrid   Alavés      W       2          2\n",
      "40 2024-05-18           Getafe   Alavés      L       0          2\n",
      "40 2024-05-26       Las Palmas   Alavés      D       1          2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/razin/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
    "\n",
    "# Load the data\n",
    "matches = pd.read_csv('morematches.csv', index_col=0)\n",
    "\n",
    "# Convert date to datetime\n",
    "matches['date'] = pd.to_datetime(matches['date'])\n",
    "\n",
    "# Calculate rolling averages for both team and opponent stats\n",
    "def calculate_rolling_averages(df, cols):\n",
    "    df = df.sort_values(by=['team', 'date'])\n",
    "    team_rolling_cols = {f'{col}_rolling': df.groupby('team')[col].transform(lambda x: x.rolling(3, closed='left').mean()) for col in cols}\n",
    "    df = df.assign(**team_rolling_cols)\n",
    "    \n",
    "    df = df.sort_values(by=['opponent', 'date'])\n",
    "    opp_rolling_cols = {f'opp_{col}_rolling': df.groupby('opponent')[col].transform(lambda x: x.rolling(3, closed='left').mean()) for col in cols}\n",
    "    df = df.assign(**opp_rolling_cols)\n",
    "    \n",
    "    # Drop rows where rolling stats could not be calculated (e.g., first few matches of each team)\n",
    "    df.dropna(subset=team_rolling_cols.keys(), inplace=True)\n",
    "    df.dropna(subset=opp_rolling_cols.keys(), inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Define columns to calculate rolling averages\n",
    "rolling_cols = ['gf', 'ga', 'sh', 'sot', 'dist', 'fk', 'pk', 'pkatt']\n",
    "\n",
    "# Apply rolling averages to the matches DataFrame\n",
    "matches = calculate_rolling_averages(matches, rolling_cols)\n",
    "\n",
    "# Encode categorical variables\n",
    "matches['venue_code'] = matches['venue'].astype('category').cat.codes\n",
    "matches['opp_code'] = matches['opponent'].astype('category').cat.codes\n",
    "matches['hour'] = matches['time'].str.replace(':', '', regex=True).astype(int)\n",
    "matches['day_code'] = matches['date'].dt.dayofweek\n",
    "\n",
    "# Define the target variable\n",
    "matches['target'] = matches['result'].apply(lambda x: 2 if x == 'W' else (1 if x == 'D' else 0))\n",
    "\n",
    "# Final list of predictors\n",
    "team_rolling_cols = [f'{col}_rolling' for col in rolling_cols]\n",
    "opp_rolling_cols = [f'opp_{col}_rolling' for col in rolling_cols]\n",
    "predictors = team_rolling_cols + opp_rolling_cols + ['venue_code', 'opp_code', 'hour', 'day_code']\n",
    "\n",
    "# Train/test split\n",
    "train = matches[matches['date'] < '2024-01-01']\n",
    "test = matches[matches['date'] >= '2024-01-01']\n",
    "\n",
    "# Initialize and fit the model\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(train[predictors], train['target'])\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions and evaluate\n",
    "preds = best_model.predict(test[predictors])\n",
    "accuracy = accuracy_score(test['target'], preds)\n",
    "precision = precision_score(test['target'], preds, average='weighted')\n",
    "\n",
    "print(f'Best Model: {best_model}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(test['target'], preds)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "# Check the training and testing target distributions\n",
    "print(f\"Training data range: {train['date'].min()} to {train['date'].max()}\")\n",
    "print(f\"Testing data range: {test['date'].min()} to {test['date'].max()}\")\n",
    "print('\\nTraining target distribution:')\n",
    "print(train['target'].value_counts(normalize=True))\n",
    "print('\\nTesting target distribution:')\n",
    "print(test['target'].value_counts(normalize=True))\n",
    "\n",
    "# Manually check predictions\n",
    "manual_check = test[['date', 'team', 'opponent', 'result', 'target']].copy()\n",
    "manual_check['predicted'] = preds\n",
    "print(manual_check.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7de437-2015-4695-9591-65f3e3fd9d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Model: RandomForestClassifier(max_depth=3, min_samples_leaf=2, random_state=1)\n",
      "Accuracy: 0.49\n",
      "Precision: 0.3681342466451071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/razin/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Feature Selection\n",
    "selector = RFECV(RandomForestClassifier(random_state=1), step=1, cv=5)\n",
    "selector.fit(train[predictors], train['target'])\n",
    "selected_features = train[predictors].columns[selector.support_]\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=50, cv=5, verbose=1, n_jobs=-1)\n",
    "random_search.fit(train[selected_features], train['target'])\n",
    "\n",
    "# Best Model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Predictions and Evaluation\n",
    "preds = best_model.predict(test[selected_features])\n",
    "accuracy = accuracy_score(test['target'], preds)\n",
    "precision = precision_score(test['target'], preds, average='weighted')\n",
    "\n",
    "print(f'Best Model: {best_model}')\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e97a74-0ff8-44e7-9532-7411d1a899af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Loss       0.50      0.57      0.53       150\n",
      "        Draw       0.00      0.00      0.00       100\n",
      "         Win       0.48      0.73      0.58       150\n",
      "\n",
      "    accuracy                           0.49       400\n",
      "   macro avg       0.33      0.44      0.37       400\n",
      "weighted avg       0.37      0.49      0.42       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/razin/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/razin/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/razin/anaconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming 'test' is your test dataset and 'preds' are the predictions\n",
    "report = classification_report(test['target'], preds, target_names=['Loss', 'Draw', 'Win'])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e502cd13-912c-41ef-bc03-2b09b1e4c70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49\n",
      "Precision: 0.4285580044138224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Loss       0.52      0.63      0.57       150\n",
      "        Draw       0.16      0.05      0.08       100\n",
      "         Win       0.52      0.65      0.57       150\n",
      "\n",
      "    accuracy                           0.49       400\n",
      "   macro avg       0.40      0.44      0.41       400\n",
      "weighted avg       0.43      0.49      0.45       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add class weights to handle imbalance\n",
    "rf = RandomForestClassifier(random_state=1, class_weight={0: 1, 1: 2, 2: 2})\n",
    "\n",
    "# Train the model with the existing predictors and the weighted classes\n",
    "rf.fit(train[selected_features], train['target'])\n",
    "\n",
    "# Predict and evaluate\n",
    "preds = rf.predict(test[selected_features])\n",
    "accuracy = accuracy_score(test['target'], preds)\n",
    "precision = precision_score(test['target'], preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(test['target'], preds, target_names=['Loss', 'Draw', 'Win'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a65cf9b-407c-476c-b24e-9daf3d6668eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.495\n",
      "Precision: 0.476060606060606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Loss       0.53      0.58      0.55       150\n",
      "        Draw       0.33      0.20      0.25       100\n",
      "         Win       0.52      0.61      0.56       150\n",
      "\n",
      "    accuracy                           0.49       400\n",
      "   macro avg       0.46      0.46      0.45       400\n",
      "weighted avg       0.48      0.49      0.48       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(train[selected_features], train['target'])\n",
    "\n",
    "# Train the model on the resampled data\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_res, y_res)\n",
    "\n",
    "# Predict and evaluate\n",
    "preds = rf.predict(test[selected_features])\n",
    "accuracy = accuracy_score(test['target'], preds)\n",
    "precision = precision_score(test['target'], preds, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(test['target'], preds, target_names=['Loss', 'Draw', 'Win'])\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62569a80-52c5-4182-a6b5-0aba444eb7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date                     0\n",
      "time                     0\n",
      "comp                     0\n",
      "round                    0\n",
      "day                      0\n",
      "venue                    0\n",
      "result               87889\n",
      "gf                   87889\n",
      "ga                   87889\n",
      "opponent                 0\n",
      "poss                 87889\n",
      "attendance           87889\n",
      "captain              87889\n",
      "formation            87889\n",
      "referee              87889\n",
      "match report             0\n",
      "notes                87889\n",
      "team                     0\n",
      "venue_code               0\n",
      "opp_code                 0\n",
      "hour                     0\n",
      "day_code                 0\n",
      "gf_rolling              38\n",
      "ga_rolling              38\n",
      "sh_rolling              38\n",
      "sot_rolling             38\n",
      "dist_rolling            38\n",
      "fk_rolling              38\n",
      "pk_rolling              38\n",
      "pkatt_rolling           38\n",
      "opp_gf_rolling          38\n",
      "opp_ga_rolling          38\n",
      "opp_sh_rolling          38\n",
      "opp_sot_rolling         38\n",
      "opp_dist_rolling        38\n",
      "opp_fk_rolling          38\n",
      "opp_pk_rolling          38\n",
      "opp_pkatt_rolling       38\n",
      "venue_code_y            38\n",
      "opp_code_y              38\n",
      "hour_y                  38\n",
      "day_code_y              38\n",
      "dtype: int64\n",
      "date                     0\n",
      "time                     0\n",
      "comp                     0\n",
      "round                    0\n",
      "day                      0\n",
      "venue                    0\n",
      "result               87889\n",
      "gf                   87889\n",
      "ga                   87889\n",
      "opponent                 0\n",
      "poss                 87889\n",
      "attendance           87889\n",
      "captain              87889\n",
      "formation            87889\n",
      "referee              87889\n",
      "match report             0\n",
      "notes                87889\n",
      "team                     0\n",
      "venue_code               0\n",
      "opp_code                 0\n",
      "hour                     0\n",
      "day_code                 0\n",
      "gf_rolling               0\n",
      "ga_rolling               0\n",
      "sh_rolling               0\n",
      "sot_rolling              0\n",
      "dist_rolling             0\n",
      "fk_rolling               0\n",
      "pk_rolling               0\n",
      "pkatt_rolling            0\n",
      "opp_gf_rolling           0\n",
      "opp_ga_rolling           0\n",
      "opp_sh_rolling           0\n",
      "opp_sot_rolling          0\n",
      "opp_dist_rolling         0\n",
      "opp_fk_rolling           0\n",
      "opp_pk_rolling           0\n",
      "opp_pkatt_rolling        0\n",
      "venue_code_y            38\n",
      "opp_code_y              38\n",
      "hour_y                  38\n",
      "day_code_y              38\n",
      "dtype: int64\n",
      "date                     0\n",
      "time                     0\n",
      "comp                     0\n",
      "round                    0\n",
      "day                      0\n",
      "venue                    0\n",
      "result               87889\n",
      "gf                   87889\n",
      "ga                   87889\n",
      "opponent                 0\n",
      "poss                 87889\n",
      "attendance           87889\n",
      "captain              87889\n",
      "formation            87889\n",
      "referee              87889\n",
      "match report             0\n",
      "notes                87889\n",
      "team                     0\n",
      "venue_code               0\n",
      "opp_code                 0\n",
      "hour                     0\n",
      "day_code                 0\n",
      "gf_rolling               0\n",
      "ga_rolling               0\n",
      "sh_rolling               0\n",
      "sot_rolling              0\n",
      "dist_rolling             0\n",
      "fk_rolling               0\n",
      "pk_rolling               0\n",
      "pkatt_rolling            0\n",
      "opp_gf_rolling           0\n",
      "opp_ga_rolling           0\n",
      "opp_sh_rolling           0\n",
      "opp_sot_rolling          0\n",
      "opp_dist_rolling         0\n",
      "opp_fk_rolling           0\n",
      "opp_pk_rolling           0\n",
      "opp_pkatt_rolling        0\n",
      "venue_code_y            38\n",
      "opp_code_y              38\n",
      "hour_y                  38\n",
      "day_code_y              38\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, classification_report\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "recent_form = pd.read_csv('morematches.csv', index_col=0)\n",
    "\n",
    "# Convert date to datetime\n",
    "recent_form['date'] = pd.to_datetime(recent_form['date'])\n",
    "\n",
    "# Calculate rolling averages\n",
    "def calculate_rolling_averages(df, cols):\n",
    "    df = df.sort_values(by='team')\n",
    "    for col in cols:\n",
    "        df[f'{col}_rolling'] = df.groupby('team')[col].transform(lambda x: x.rolling(3, closed='left').mean())\n",
    "    df = df.sort_values(by='opponent')\n",
    "    for col in cols:\n",
    "        df[f'opp_{col}_rolling'] = df.groupby('opponent')[col].transform(lambda x: x.rolling(3, closed='left').mean())\n",
    "    return df\n",
    "\n",
    "rolling_cols = ['gf', 'ga', 'sh', 'sot', 'dist', 'fk', 'pk', 'pkatt']\n",
    "recent_form = calculate_rolling_averages(recent_form, rolling_cols)\n",
    "\n",
    "# Drop rows where rolling stats could not be calculated\n",
    "drop_columns = [f'{col}_rolling' for col in rolling_cols] + [f'opp_{col}_rolling' for col in rolling_cols]\n",
    "recent_form = recent_form.dropna(subset=drop_columns)\n",
    "\n",
    "# Define the target variable\n",
    "recent_form['target'] = recent_form['result'].apply(lambda x: 2 if x == 'W' else 1 if x == 'D' else 0)\n",
    "\n",
    "# Encode categorical variables for recent form\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "recent_form['venue_code'] = recent_form['venue'].astype('category').cat.codes\n",
    "recent_form['opp_code'] = recent_form['opponent'].astype('category').cat.codes\n",
    "recent_form['hour'] = recent_form['time'].str.replace(':', '', regex=True).astype(int)\n",
    "recent_form['day_code'] = recent_form['date'].dt.dayofweek\n",
    "\n",
    "new_season = pd.read_csv('LaLiga2024-2025.csv')\n",
    "\n",
    "# Fill missing time with midnight for new season data\n",
    "new_season['time'] = new_season['time'].fillna('00:00')\n",
    "new_season['date'] = pd.to_datetime(new_season['date'] + ' ' + new_season['time'])\n",
    "\n",
    "# Encode categorical variables for new season\n",
    "new_season['venue_code'] = new_season['venue'].astype('category').cat.codes\n",
    "new_season['opp_code'] = new_season['opponent'].astype('category').cat.codes\n",
    "new_season['hour'] = new_season['time'].str.replace(':', '', regex=True).astype(int)\n",
    "new_season['day_code'] = new_season['date'].dt.dayofweek\n",
    "\n",
    "# Define predictors\n",
    "predictors = [f'{col}_rolling' for col in rolling_cols] + [f'opp_{col}_rolling' for col in rolling_cols] + ['venue_code', 'opp_code', 'hour', 'day_code']\n",
    "\n",
    "new_season = pd.merge(new_season, recent_form[['team'] + predictors], on='team', how='left')\n",
    "\n",
    "# Rename columns to ensure consistency\n",
    "new_season.rename(columns={'venue_code_x': 'venue_code', 'opp_code_x': 'opp_code', 'hour_x': 'hour', 'day_code_x': 'day_code'}, inplace=True)\n",
    "\n",
    "# Fill missing values in new season data with the mean of each column\n",
    "new_season[predictors] = new_season[predictors].fillna(new_season[predictors].mean())\n",
    "\n",
    "# Drop rows with NaN values if still present\n",
    "new_season = new_season.dropna(subset=predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5a46862a-edd9-449d-8672-e3d55f10c380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight={0: 1, 1: 2, 2: 2}, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight={0: 1, 1: 2, 2: 2}, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1, 1: 2, 2: 2}, random_state=1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1, class_weight={0: 1, 1: 2, 2: 2})\n",
    "rf.fit(recent_form[predictors], recent_form['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c91a1a89-b768-4010-aa37-6a6352197410",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = rf.predict(new_season[predictors])\n",
    "new_season['predicted'] = new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5863ff50-639d-4746-904f-e71e03f624c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_season.to_csv('predicted_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9466c407-1d04-4a04-b2c9-0dafb3c5441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted La Liga 2024-2025 Standings\n",
      "               Team  Wins  Draws  Losses\n",
      "0       Real Madrid    25      8       5\n",
      "1         Barcelona    24      9       5\n",
      "2   Atlético Madrid    22     10       6\n",
      "3           Sevilla    21      9       8\n",
      "4        Villarreal    20      8      10\n",
      "5            Girona    19     10       9\n",
      "6     Real Sociedad    18     11       9\n",
      "7     Athletic Club    17     11      10\n",
      "8          Valencia    15     12      11\n",
      "9             Betis    15     11      12\n",
      "10          Osasuna    14     12      12\n",
      "11         Mallorca    13     13      12\n",
      "12           Getafe    13     12      13\n",
      "13         Espanyol    12     12      14\n",
      "14   Rayo Vallecano    11     12      15\n",
      "15       Celta Vigo    10     11      17\n",
      "16       Valladolid     9     11      18\n",
      "17       Las Palmas     8     10      20\n",
      "18           Alavés     7     10      21\n",
      "19          Leganés     5     10      23\n"
     ]
    }
   ],
   "source": [
    "#Results gathered from csv\n",
    "\n",
    "# Define the predicted standings and results\n",
    "predicted_standings = {\n",
    "    'Team': [\n",
    "        \"Real Madrid\", \"Barcelona\", \"Atlético Madrid\", \"Sevilla\", \"Villarreal\", \n",
    "        \"Girona\", \"Real Sociedad\", \"Athletic Club\", \"Valencia\", \"Betis\", \n",
    "        \"Osasuna\", \"Mallorca\", \"Getafe\", \"Espanyol\", \"Rayo Vallecano\", \n",
    "        \"Celta Vigo\", \"Valladolid\", \"Las Palmas\", \"Alavés\", \"Leganés\"\n",
    "    ],\n",
    "    'Wins': [\n",
    "        25, 24, 22, 21, 20, \n",
    "        19, 18, 17, 15, 15, \n",
    "        14, 13, 13, 12, 11, \n",
    "        10, 9, 8, 7, 5\n",
    "    ],\n",
    "    'Draws': [\n",
    "        8, 9, 10, 9, 8, \n",
    "        10, 11, 11, 12, 11, \n",
    "        12, 13, 12, 12, 12, \n",
    "        11, 11, 10, 10, 10\n",
    "    ],\n",
    "    'Losses': [\n",
    "        5, 5, 6, 8, 10, \n",
    "        9, 9, 10, 11, 12, \n",
    "        12, 12, 13, 14, 15, \n",
    "        17, 18, 20, 21, 23\n",
    "    ]\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with the predicted standings\n",
    "standings_df = pd.DataFrame(predicted_standings)\n",
    "\n",
    "# Print the standings\n",
    "print(\"Predicted La Liga 2024-2025 Standings\")\n",
    "print(standings_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e242ec-d456-4f5b-964a-78ba2c132a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
